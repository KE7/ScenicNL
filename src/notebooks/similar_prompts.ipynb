{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install np sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# https://www.sbert.net/ example model - \"all-MiniLM-L6-v2\"\n",
    "sentence_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def compute_description_encodings(data):\n",
    "    vectors = sentence_encoder.encode([d['description'] for d in data], show_progress_bar=False)\n",
    "    for example, vector in zip(data, vectors):\n",
    "        # save this embedding as a new key\n",
    "        example['description_encoding'] = np.array(vector)\n",
    "\n",
    "\n",
    "def select_similar_descriptions(new_description, few_shot_data, num_examples=4):\n",
    "    # Recall that in few-shot prompting, the best example should be the most recent one.\n",
    "    \n",
    "    description_vector = sentence_encoder.encode(new_description, show_progress_bar=False)\n",
    "    vectors = [d['description_encoding'] for d in few_shot_data]\n",
    "\n",
    "    # TODO: pick the best similarity metric. cosine dist is okay for now\n",
    "    cos_sim = np.sum(vectors * description_vector, axis=1)\n",
    "    best_indices = np.argsort(cos_sim)[-num_examples:]\n",
    "    return [few_shot_data[i] for i in best_indices]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
